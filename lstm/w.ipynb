{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a61b4af6-53b5-4b37-a118-8bbf15354338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, Bidirectional\n",
    "from keras.optimizers import SGD\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2598ed41-c2b3-4ffa-8c13-7bd9803361e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../datasets/INFY.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0015ea2d-e45a-489a-9bfa-37323d3fa502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>INFY</th>\n",
       "      <th>Close</th>\n",
       "      <th>Net Sales/Income from operations</th>\n",
       "      <th>Employees Cost</th>\n",
       "      <th>depreciat</th>\n",
       "      <th>Other Expenses</th>\n",
       "      <th>Other Income</th>\n",
       "      <th>P/L Before Tax</th>\n",
       "      <th>P/L After Tax</th>\n",
       "      <th>Net Profit/(Loss) For the Period</th>\n",
       "      <th>Equity Share Capital</th>\n",
       "      <th>Basic EPS</th>\n",
       "      <th>ROE</th>\n",
       "      <th>ROCE</th>\n",
       "      <th>ROA</th>\n",
       "      <th>Quick Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mar '04</th>\n",
       "      <td>51.045002</td>\n",
       "      <td>1308.90</td>\n",
       "      <td>620.53</td>\n",
       "      <td>62.08</td>\n",
       "      <td>69.36</td>\n",
       "      <td>3.18</td>\n",
       "      <td>387.05</td>\n",
       "      <td>337.05</td>\n",
       "      <td>337.05</td>\n",
       "      <td>33.32</td>\n",
       "      <td>186.60</td>\n",
       "      <td>38.22</td>\n",
       "      <td>38.22</td>\n",
       "      <td>24.20</td>\n",
       "      <td>1.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jun '04</th>\n",
       "      <td>59.861252</td>\n",
       "      <td>1471.39</td>\n",
       "      <td>691.27</td>\n",
       "      <td>49.38</td>\n",
       "      <td>100.64</td>\n",
       "      <td>17.99</td>\n",
       "      <td>459.47</td>\n",
       "      <td>394.47</td>\n",
       "      <td>394.47</td>\n",
       "      <td>33.43</td>\n",
       "      <td>186.60</td>\n",
       "      <td>38.22</td>\n",
       "      <td>38.22</td>\n",
       "      <td>24.20</td>\n",
       "      <td>1.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sep '04</th>\n",
       "      <td>67.139999</td>\n",
       "      <td>1689.56</td>\n",
       "      <td>779.55</td>\n",
       "      <td>56.55</td>\n",
       "      <td>130.41</td>\n",
       "      <td>30.23</td>\n",
       "      <td>533.35</td>\n",
       "      <td>454.85</td>\n",
       "      <td>454.85</td>\n",
       "      <td>133.93</td>\n",
       "      <td>186.60</td>\n",
       "      <td>38.22</td>\n",
       "      <td>38.22</td>\n",
       "      <td>24.20</td>\n",
       "      <td>1.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dec '04</th>\n",
       "      <td>84.240005</td>\n",
       "      <td>1798.52</td>\n",
       "      <td>856.62</td>\n",
       "      <td>69.38</td>\n",
       "      <td>103.53</td>\n",
       "      <td>46.77</td>\n",
       "      <td>588.97</td>\n",
       "      <td>495.97</td>\n",
       "      <td>495.97</td>\n",
       "      <td>134.73</td>\n",
       "      <td>186.60</td>\n",
       "      <td>38.22</td>\n",
       "      <td>38.22</td>\n",
       "      <td>24.20</td>\n",
       "      <td>1.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mar '05</th>\n",
       "      <td>75.481880</td>\n",
       "      <td>1900.19</td>\n",
       "      <td>854.56</td>\n",
       "      <td>92.91</td>\n",
       "      <td>138.35</td>\n",
       "      <td>32.51</td>\n",
       "      <td>602.70</td>\n",
       "      <td>513.90</td>\n",
       "      <td>559.09</td>\n",
       "      <td>135.29</td>\n",
       "      <td>70.21</td>\n",
       "      <td>36.24</td>\n",
       "      <td>36.24</td>\n",
       "      <td>28.83</td>\n",
       "      <td>2.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jun '23</th>\n",
       "      <td>389.149994</td>\n",
       "      <td>31811.00</td>\n",
       "      <td>16353.00</td>\n",
       "      <td>746.00</td>\n",
       "      <td>7524.00</td>\n",
       "      <td>1001.00</td>\n",
       "      <td>8146.00</td>\n",
       "      <td>5956.00</td>\n",
       "      <td>5956.00</td>\n",
       "      <td>2075.00</td>\n",
       "      <td>55.48</td>\n",
       "      <td>34.34</td>\n",
       "      <td>43.03</td>\n",
       "      <td>22.96</td>\n",
       "      <td>1.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sep '23</th>\n",
       "      <td>406.049988</td>\n",
       "      <td>32629.00</td>\n",
       "      <td>16435.00</td>\n",
       "      <td>738.00</td>\n",
       "      <td>8200.00</td>\n",
       "      <td>1350.00</td>\n",
       "      <td>8517.00</td>\n",
       "      <td>6245.00</td>\n",
       "      <td>6245.00</td>\n",
       "      <td>2075.00</td>\n",
       "      <td>55.48</td>\n",
       "      <td>34.34</td>\n",
       "      <td>43.03</td>\n",
       "      <td>22.96</td>\n",
       "      <td>1.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dec '23</th>\n",
       "      <td>471.299988</td>\n",
       "      <td>32491.00</td>\n",
       "      <td>16304.00</td>\n",
       "      <td>738.00</td>\n",
       "      <td>8073.00</td>\n",
       "      <td>1582.00</td>\n",
       "      <td>8876.00</td>\n",
       "      <td>6552.00</td>\n",
       "      <td>6552.00</td>\n",
       "      <td>2075.00</td>\n",
       "      <td>55.48</td>\n",
       "      <td>34.34</td>\n",
       "      <td>43.03</td>\n",
       "      <td>22.96</td>\n",
       "      <td>1.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mar '24</th>\n",
       "      <td>480.100006</td>\n",
       "      <td>32001.00</td>\n",
       "      <td>16047.00</td>\n",
       "      <td>722.00</td>\n",
       "      <td>8239.00</td>\n",
       "      <td>3483.00</td>\n",
       "      <td>10414.00</td>\n",
       "      <td>8480.00</td>\n",
       "      <td>8480.00</td>\n",
       "      <td>2075.00</td>\n",
       "      <td>65.62</td>\n",
       "      <td>33.54</td>\n",
       "      <td>41.23</td>\n",
       "      <td>23.69</td>\n",
       "      <td>2.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jun '24</th>\n",
       "      <td>514.849976</td>\n",
       "      <td>33283.00</td>\n",
       "      <td>16495.00</td>\n",
       "      <td>698.00</td>\n",
       "      <td>8624.00</td>\n",
       "      <td>721.00</td>\n",
       "      <td>8128.00</td>\n",
       "      <td>5768.00</td>\n",
       "      <td>5768.00</td>\n",
       "      <td>2076.00</td>\n",
       "      <td>65.62</td>\n",
       "      <td>33.54</td>\n",
       "      <td>41.23</td>\n",
       "      <td>23.69</td>\n",
       "      <td>2.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "INFY          Close  Net Sales/Income from operations  Employees Cost  \\\n",
       "Mar '04   51.045002                           1308.90          620.53   \n",
       "Jun '04   59.861252                           1471.39          691.27   \n",
       "Sep '04   67.139999                           1689.56          779.55   \n",
       "Dec '04   84.240005                           1798.52          856.62   \n",
       "Mar '05   75.481880                           1900.19          854.56   \n",
       "...             ...                               ...             ...   \n",
       "Jun '23  389.149994                          31811.00        16353.00   \n",
       "Sep '23  406.049988                          32629.00        16435.00   \n",
       "Dec '23  471.299988                          32491.00        16304.00   \n",
       "Mar '24  480.100006                          32001.00        16047.00   \n",
       "Jun '24  514.849976                          33283.00        16495.00   \n",
       "\n",
       "INFY     depreciat  Other Expenses  Other Income  P/L Before Tax  \\\n",
       "Mar '04      62.08           69.36          3.18          387.05   \n",
       "Jun '04      49.38          100.64         17.99          459.47   \n",
       "Sep '04      56.55          130.41         30.23          533.35   \n",
       "Dec '04      69.38          103.53         46.77          588.97   \n",
       "Mar '05      92.91          138.35         32.51          602.70   \n",
       "...            ...             ...           ...             ...   \n",
       "Jun '23     746.00         7524.00       1001.00         8146.00   \n",
       "Sep '23     738.00         8200.00       1350.00         8517.00   \n",
       "Dec '23     738.00         8073.00       1582.00         8876.00   \n",
       "Mar '24     722.00         8239.00       3483.00        10414.00   \n",
       "Jun '24     698.00         8624.00        721.00         8128.00   \n",
       "\n",
       "INFY     P/L After Tax  Net Profit/(Loss) For the Period  \\\n",
       "Mar '04         337.05                            337.05   \n",
       "Jun '04         394.47                            394.47   \n",
       "Sep '04         454.85                            454.85   \n",
       "Dec '04         495.97                            495.97   \n",
       "Mar '05         513.90                            559.09   \n",
       "...                ...                               ...   \n",
       "Jun '23        5956.00                           5956.00   \n",
       "Sep '23        6245.00                           6245.00   \n",
       "Dec '23        6552.00                           6552.00   \n",
       "Mar '24        8480.00                           8480.00   \n",
       "Jun '24        5768.00                           5768.00   \n",
       "\n",
       "INFY     Equity Share Capital  Basic EPS    ROE   ROCE    ROA  Quick Ratio  \n",
       "Mar '04                 33.32     186.60  38.22  38.22  24.20         1.65  \n",
       "Jun '04                 33.43     186.60  38.22  38.22  24.20         1.65  \n",
       "Sep '04                133.93     186.60  38.22  38.22  24.20         1.65  \n",
       "Dec '04                134.73     186.60  38.22  38.22  24.20         1.65  \n",
       "Mar '05                135.29      70.21  36.24  36.24  28.83         2.77  \n",
       "...                       ...        ...    ...    ...    ...          ...  \n",
       "Jun '23               2075.00      55.48  34.34  43.03  22.96         1.90  \n",
       "Sep '23               2075.00      55.48  34.34  43.03  22.96         1.90  \n",
       "Dec '23               2075.00      55.48  34.34  43.03  22.96         1.90  \n",
       "Mar '24               2075.00      65.62  33.54  41.23  23.69         2.62  \n",
       "Jun '24               2076.00      65.62  33.54  41.23  23.69         2.62  \n",
       "\n",
       "[82 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.set_index(df.columns[0], inplace=True)\n",
    "df = df.T\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97294b5d-807d-457a-8c62-1f2f8a941a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "close_column = df['Close']\n",
    "\n",
    "columns_to_scale = df.columns.difference(['Close'])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df[columns_to_scale] = scaler.fit_transform(df[columns_to_scale])\n",
    "\n",
    "df['Close'] = close_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bda5d2cd-993b-465a-bdde-075d173a1c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>INFY</th>\n",
       "      <th>Close</th>\n",
       "      <th>Net Sales/Income from operations</th>\n",
       "      <th>Employees Cost</th>\n",
       "      <th>depreciat</th>\n",
       "      <th>Other Expenses</th>\n",
       "      <th>Other Income</th>\n",
       "      <th>P/L Before Tax</th>\n",
       "      <th>P/L After Tax</th>\n",
       "      <th>Net Profit/(Loss) For the Period</th>\n",
       "      <th>Equity Share Capital</th>\n",
       "      <th>Basic EPS</th>\n",
       "      <th>ROE</th>\n",
       "      <th>ROCE</th>\n",
       "      <th>ROA</th>\n",
       "      <th>Quick Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mar '04</th>\n",
       "      <td>51.045002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.784111</td>\n",
       "      <td>0.585593</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jun '04</th>\n",
       "      <td>59.861252</td>\n",
       "      <td>0.005082</td>\n",
       "      <td>0.004456</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003656</td>\n",
       "      <td>0.005736</td>\n",
       "      <td>0.007223</td>\n",
       "      <td>0.007051</td>\n",
       "      <td>0.007051</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.784111</td>\n",
       "      <td>0.585593</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sep '04</th>\n",
       "      <td>67.139999</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.010017</td>\n",
       "      <td>0.010293</td>\n",
       "      <td>0.007136</td>\n",
       "      <td>0.009248</td>\n",
       "      <td>0.014591</td>\n",
       "      <td>0.014467</td>\n",
       "      <td>0.014467</td>\n",
       "      <td>0.046781</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.784111</td>\n",
       "      <td>0.585593</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dec '04</th>\n",
       "      <td>84.240005</td>\n",
       "      <td>0.015313</td>\n",
       "      <td>0.014872</td>\n",
       "      <td>0.028710</td>\n",
       "      <td>0.003994</td>\n",
       "      <td>0.013994</td>\n",
       "      <td>0.020138</td>\n",
       "      <td>0.019516</td>\n",
       "      <td>0.019516</td>\n",
       "      <td>0.047153</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.784111</td>\n",
       "      <td>0.585593</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mar '05</th>\n",
       "      <td>75.481880</td>\n",
       "      <td>0.018493</td>\n",
       "      <td>0.014743</td>\n",
       "      <td>0.062487</td>\n",
       "      <td>0.008065</td>\n",
       "      <td>0.009902</td>\n",
       "      <td>0.021507</td>\n",
       "      <td>0.021718</td>\n",
       "      <td>0.027268</td>\n",
       "      <td>0.047413</td>\n",
       "      <td>0.238983</td>\n",
       "      <td>0.889447</td>\n",
       "      <td>0.695242</td>\n",
       "      <td>0.977966</td>\n",
       "      <td>0.308540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jun '23</th>\n",
       "      <td>389.149994</td>\n",
       "      <td>0.953963</td>\n",
       "      <td>0.991055</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871415</td>\n",
       "      <td>0.287805</td>\n",
       "      <td>0.773810</td>\n",
       "      <td>0.690039</td>\n",
       "      <td>0.690039</td>\n",
       "      <td>0.949318</td>\n",
       "      <td>0.142670</td>\n",
       "      <td>0.783361</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.480508</td>\n",
       "      <td>0.068871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sep '23</th>\n",
       "      <td>406.049988</td>\n",
       "      <td>0.979546</td>\n",
       "      <td>0.996220</td>\n",
       "      <td>0.988516</td>\n",
       "      <td>0.950436</td>\n",
       "      <td>0.387948</td>\n",
       "      <td>0.810810</td>\n",
       "      <td>0.725529</td>\n",
       "      <td>0.725529</td>\n",
       "      <td>0.949318</td>\n",
       "      <td>0.142670</td>\n",
       "      <td>0.783361</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.480508</td>\n",
       "      <td>0.068871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dec '23</th>\n",
       "      <td>471.299988</td>\n",
       "      <td>0.975230</td>\n",
       "      <td>0.987968</td>\n",
       "      <td>0.988516</td>\n",
       "      <td>0.935591</td>\n",
       "      <td>0.454519</td>\n",
       "      <td>0.846613</td>\n",
       "      <td>0.763231</td>\n",
       "      <td>0.763231</td>\n",
       "      <td>0.949318</td>\n",
       "      <td>0.142670</td>\n",
       "      <td>0.783361</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.480508</td>\n",
       "      <td>0.068871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mar '24</th>\n",
       "      <td>480.100006</td>\n",
       "      <td>0.959905</td>\n",
       "      <td>0.971779</td>\n",
       "      <td>0.965548</td>\n",
       "      <td>0.954995</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.949318</td>\n",
       "      <td>0.208971</td>\n",
       "      <td>0.738693</td>\n",
       "      <td>0.919210</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.267218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jun '24</th>\n",
       "      <td>514.849976</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.931096</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.207461</td>\n",
       "      <td>0.772014</td>\n",
       "      <td>0.666951</td>\n",
       "      <td>0.666951</td>\n",
       "      <td>0.949783</td>\n",
       "      <td>0.208971</td>\n",
       "      <td>0.738693</td>\n",
       "      <td>0.919210</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.267218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "INFY          Close  Net Sales/Income from operations  Employees Cost  \\\n",
       "Mar '04   51.045002                          0.000000        0.000000   \n",
       "Jun '04   59.861252                          0.005082        0.004456   \n",
       "Sep '04   67.139999                          0.011905        0.010017   \n",
       "Dec '04   84.240005                          0.015313        0.014872   \n",
       "Mar '05   75.481880                          0.018493        0.014743   \n",
       "...             ...                               ...             ...   \n",
       "Jun '23  389.149994                          0.953963        0.991055   \n",
       "Sep '23  406.049988                          0.979546        0.996220   \n",
       "Dec '23  471.299988                          0.975230        0.987968   \n",
       "Mar '24  480.100006                          0.959905        0.971779   \n",
       "Jun '24  514.849976                          1.000000        1.000000   \n",
       "\n",
       "INFY     depreciat  Other Expenses  Other Income  P/L Before Tax  \\\n",
       "Mar '04   0.018231        0.000000      0.001486        0.000000   \n",
       "Jun '04   0.000000        0.003656      0.005736        0.007223   \n",
       "Sep '04   0.010293        0.007136      0.009248        0.014591   \n",
       "Dec '04   0.028710        0.003994      0.013994        0.020138   \n",
       "Mar '05   0.062487        0.008065      0.009902        0.021507   \n",
       "...            ...             ...           ...             ...   \n",
       "Jun '23   1.000000        0.871415      0.287805        0.773810   \n",
       "Sep '23   0.988516        0.950436      0.387948        0.810810   \n",
       "Dec '23   0.988516        0.935591      0.454519        0.846613   \n",
       "Mar '24   0.965548        0.954995      1.000000        1.000000   \n",
       "Jun '24   0.931096        1.000000      0.207461        0.772014   \n",
       "\n",
       "INFY     P/L After Tax  Net Profit/(Loss) For the Period  \\\n",
       "Mar '04       0.000000                          0.000000   \n",
       "Jun '04       0.007051                          0.007051   \n",
       "Sep '04       0.014467                          0.014467   \n",
       "Dec '04       0.019516                          0.019516   \n",
       "Mar '05       0.021718                          0.027268   \n",
       "...                ...                               ...   \n",
       "Jun '23       0.690039                          0.690039   \n",
       "Sep '23       0.725529                          0.725529   \n",
       "Dec '23       0.763231                          0.763231   \n",
       "Mar '24       1.000000                          1.000000   \n",
       "Jun '24       0.666951                          0.666951   \n",
       "\n",
       "INFY     Equity Share Capital  Basic EPS       ROE      ROCE       ROA  \\\n",
       "Mar '04              0.000000   1.000000  1.000000  0.784111  0.585593   \n",
       "Jun '04              0.000051   1.000000  1.000000  0.784111  0.585593   \n",
       "Sep '04              0.046781   1.000000  1.000000  0.784111  0.585593   \n",
       "Dec '04              0.047153   1.000000  1.000000  0.784111  0.585593   \n",
       "Mar '05              0.047413   0.238983  0.889447  0.695242  0.977966   \n",
       "...                       ...        ...       ...       ...       ...   \n",
       "Jun '23              0.949318   0.142670  0.783361  1.000000  0.480508   \n",
       "Sep '23              0.949318   0.142670  0.783361  1.000000  0.480508   \n",
       "Dec '23              0.949318   0.142670  0.783361  1.000000  0.480508   \n",
       "Mar '24              0.949318   0.208971  0.738693  0.919210  0.542373   \n",
       "Jun '24              0.949783   0.208971  0.738693  0.919210  0.542373   \n",
       "\n",
       "INFY     Quick Ratio  \n",
       "Mar '04     0.000000  \n",
       "Jun '04     0.000000  \n",
       "Sep '04     0.000000  \n",
       "Dec '04     0.000000  \n",
       "Mar '05     0.308540  \n",
       "...              ...  \n",
       "Jun '23     0.068871  \n",
       "Sep '23     0.068871  \n",
       "Dec '23     0.068871  \n",
       "Mar '24     0.267218  \n",
       "Jun '24     0.267218  \n",
       "\n",
       "[82 rows x 15 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebd98094-7392-4aec-93da-6442ae51de76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(df, sequence_length):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    for i in range(len(df) - sequence_length):\n",
    "        sequence = df.iloc[i:i + sequence_length].drop(columns=['Close'])\n",
    "        label = df['Close'].iloc[i + sequence_length]\n",
    "        sequences.append(sequence.values)\n",
    "        labels.append(label)\n",
    "    return np.array(sequences), np.array(labels)\n",
    "\n",
    "sequence_length = 30\n",
    "\n",
    "X, y = create_sequences(df, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1eb3e089-ba9e-46a3-ada4-200ca803a253",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = create_sequences(df, sequence_length)\n",
    "\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, y_train = X[:train_size], y[:train_size]\n",
    "X_test, y_test = X[train_size:], y[train_size:]\n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], X_test.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af85e111-4124-40dd-accc-0549610d7ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(LSTM(50, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(25))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a3e7f77-1a22-4d39-aef6-cbe5e566c11a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 18460.0000 - val_loss: 112844.0703\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 17803.5977 - val_loss: 111747.7734\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 16032.9834 - val_loss: 110666.8203\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 16330.9219 - val_loss: 109581.1719\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 17015.1699 - val_loss: 108505.0000\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 15255.1367 - val_loss: 107446.8828\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 15354.5215 - val_loss: 106419.8984\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 16034.9785 - val_loss: 105395.7734\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 15604.8213 - val_loss: 104397.4297\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 15099.2773 - val_loss: 103415.5312\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 14601.8916 - val_loss: 102418.2031\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 14553.1895 - val_loss: 101462.0469\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 14781.7334 - val_loss: 100526.5234\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 14503.5791 - val_loss: 99630.0703\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 13640.0049 - val_loss: 98745.0234\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 13178.3418 - val_loss: 97864.4297\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 13426.9219 - val_loss: 96975.7578\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 13397.3477 - val_loss: 96074.3516\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 13018.9111 - val_loss: 95184.8672\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 13624.8096 - val_loss: 94304.7188\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 12311.6953 - val_loss: 93451.5938\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 12690.9766 - val_loss: 92650.5312\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 12307.5918 - val_loss: 91885.1094\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 12637.0322 - val_loss: 91155.5625\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 11883.3633 - val_loss: 90411.2031\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 12426.2432 - val_loss: 89622.5000\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 12182.3867 - val_loss: 88870.5234\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 11821.0762 - val_loss: 88143.3516\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 11834.7930 - val_loss: 87446.6562\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 11482.9131 - val_loss: 86771.3281\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 11976.9609 - val_loss: 86092.5938\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 10686.4121 - val_loss: 85448.9219\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 11581.3008 - val_loss: 84843.4297\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 11704.8730 - val_loss: 84247.4219\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 11009.7588 - val_loss: 83625.9844\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 11572.4922 - val_loss: 83012.6484\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 11401.3105 - val_loss: 82430.5312\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 11633.8975 - val_loss: 81852.4141\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 10973.1445 - val_loss: 81269.1953\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 11155.2168 - val_loss: 80698.1328\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 10823.5273 - val_loss: 80164.3906\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 10900.1445 - val_loss: 79647.6797\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 10715.9092 - val_loss: 79156.1562\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 10314.9082 - val_loss: 78699.8281\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 10049.1279 - val_loss: 78292.0781\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 9979.6660 - val_loss: 77887.1562\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 10908.4727 - val_loss: 77471.2734\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 11277.8486 - val_loss: 77029.2500\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 9982.3721 - val_loss: 76575.5547\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 10228.1309 - val_loss: 76148.1562\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 11117.1924 - val_loss: 75773.7031\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 11258.6895 - val_loss: 75425.0625\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 10457.9092 - val_loss: 75114.8750\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 10372.9775 - val_loss: 74781.5078\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 10730.9219 - val_loss: 74460.1406\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 10453.7139 - val_loss: 74170.1016\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 10270.2900 - val_loss: 73871.1797\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 10385.9707 - val_loss: 73581.0859\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 10176.1689 - val_loss: 73312.8672\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 9710.8057 - val_loss: 73061.4453\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 9597.3242 - val_loss: 72840.4531\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 10498.2588 - val_loss: 72609.9531\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 10734.7578 - val_loss: 72360.7578\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 10612.2275 - val_loss: 72128.0312\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 10128.3564 - val_loss: 71876.0547\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 9245.0576 - val_loss: 71644.8203\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 10374.1523 - val_loss: 71386.5703\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 10438.1953 - val_loss: 71124.5234\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 10600.1631 - val_loss: 70885.2812\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 10145.1367 - val_loss: 70678.9219\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 10764.2891 - val_loss: 70477.2109\n",
      "Epoch 72/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 9380.5215 - val_loss: 70249.5781\n",
      "Epoch 73/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 9723.3232 - val_loss: 70009.1641\n",
      "Epoch 74/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 9936.2764 - val_loss: 69749.9531\n",
      "Epoch 75/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 10319.3164 - val_loss: 69494.1562\n",
      "Epoch 76/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 10250.2070 - val_loss: 69238.7578\n",
      "Epoch 77/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 9435.6895 - val_loss: 69010.1328\n",
      "Epoch 78/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 10594.3154 - val_loss: 68836.1719\n",
      "Epoch 79/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 10436.9727 - val_loss: 68719.1328\n",
      "Epoch 80/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 10955.2939 - val_loss: 68623.3438\n",
      "Epoch 81/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 10067.7285 - val_loss: 68503.8516\n",
      "Epoch 82/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 10232.3184 - val_loss: 68415.0312\n",
      "Epoch 83/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 10125.7549 - val_loss: 68287.4297\n",
      "Epoch 84/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 10214.5068 - val_loss: 68176.9688\n",
      "Epoch 85/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 9673.3467 - val_loss: 68109.4375\n",
      "Epoch 86/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 9995.8057 - val_loss: 68041.9688\n",
      "Epoch 87/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 10288.6885 - val_loss: 68003.0703\n",
      "Epoch 88/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 10420.0840 - val_loss: 67974.7578\n",
      "Epoch 89/1000\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 8871.9844 - val_loss: 67944.5078\n",
      "Epoch 90/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 10110.2988 - val_loss: 67916.7578\n",
      "Epoch 91/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 9231.9863 - val_loss: 67891.8438\n",
      "Epoch 92/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 9623.3555 - val_loss: 67872.7812\n",
      "Epoch 93/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 9067.5986 - val_loss: 67846.8047\n",
      "Epoch 94/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 9504.6006 - val_loss: 67820.4062\n",
      "Epoch 95/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 10178.6572 - val_loss: 67805.4062\n",
      "Epoch 96/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 9957.0957 - val_loss: 67795.0312\n",
      "Epoch 97/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 10666.2129 - val_loss: 67786.3984\n",
      "Epoch 98/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 9800.4043 - val_loss: 67758.1328\n",
      "Epoch 99/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 10295.7070 - val_loss: 67727.0078\n",
      "Epoch 100/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 10267.0850 - val_loss: 67650.8984\n",
      "Epoch 101/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 10372.4805 - val_loss: 67584.2969\n",
      "Epoch 102/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 9670.5498 - val_loss: 67523.5703\n",
      "Epoch 103/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 10118.6748 - val_loss: 67404.8438\n",
      "Epoch 104/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 10287.2109 - val_loss: 67288.1172\n",
      "Epoch 105/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 9950.8662 - val_loss: 67178.1172\n",
      "Epoch 106/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 10468.1758 - val_loss: 67106.6562\n",
      "Epoch 107/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 10174.7471 - val_loss: 67032.7734\n",
      "Epoch 108/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 10338.5293 - val_loss: 66976.0703\n",
      "Epoch 109/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 10488.1602 - val_loss: 66966.4844\n",
      "Epoch 110/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 9993.1250 - val_loss: 66969.7422\n",
      "Epoch 111/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 10230.1357 - val_loss: 66983.6719\n",
      "Epoch 112/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 11501.4365 - val_loss: 66967.3281\n",
      "Epoch 113/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 10116.7832 - val_loss: 66911.1406\n",
      "Epoch 114/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 9395.2178 - val_loss: 66862.5469\n",
      "Epoch 115/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 10354.2432 - val_loss: 66855.4453\n",
      "Epoch 116/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 10743.4180 - val_loss: 66882.6562\n",
      "Epoch 117/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 10381.1895 - val_loss: 66871.2188\n",
      "Epoch 118/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 9995.0156 - val_loss: 66802.9297\n",
      "Epoch 119/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 9677.0430 - val_loss: 66707.4062\n",
      "Epoch 120/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 9634.8662 - val_loss: 66589.6797\n",
      "Epoch 121/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 10198.2344 - val_loss: 66514.5938\n",
      "Epoch 122/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 10539.2705 - val_loss: 66485.9219\n",
      "Epoch 123/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 10528.6191 - val_loss: 66504.0078\n",
      "Epoch 124/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 9601.0742 - val_loss: 66529.3672\n",
      "Epoch 125/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 9799.8115 - val_loss: 66547.3516\n",
      "Epoch 126/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 9610.6289 - val_loss: 66586.0234\n",
      "Epoch 127/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 9587.5049 - val_loss: 66646.2188\n",
      "Epoch 128/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 9637.8467 - val_loss: 66686.9688\n",
      "Epoch 129/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 10359.7900 - val_loss: 66720.2969\n",
      "Epoch 130/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 10140.3184 - val_loss: 66731.2734\n",
      "Epoch 131/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 10688.2617 - val_loss: 66724.1094\n",
      "Epoch 132/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 9123.1709 - val_loss: 66678.3438\n",
      "Epoch 133/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 11413.8457 - val_loss: 66641.3828\n",
      "Epoch 134/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 10114.5020 - val_loss: 66581.5156\n",
      "Epoch 135/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 10259.2256 - val_loss: 66529.7188\n",
      "Epoch 136/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 12169.2031 - val_loss: 66512.9922\n",
      "Epoch 137/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 9669.8232 - val_loss: 66492.2578\n",
      "Epoch 138/1000\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 10169.6318 - val_loss: 66438.2734\n",
      "Epoch 139/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 8677.1553 - val_loss: 66347.2578\n",
      "Epoch 140/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 9418.7578 - val_loss: 66267.5000\n",
      "Epoch 141/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 10488.0391 - val_loss: 66174.6016\n",
      "Epoch 142/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 10049.0293 - val_loss: 66047.0234\n",
      "Epoch 143/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 9816.8320 - val_loss: 65951.5469\n",
      "Epoch 144/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 10319.6436 - val_loss: 65784.7266\n",
      "Epoch 145/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 10180.3203 - val_loss: 65555.6172\n",
      "Epoch 146/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 10235.7412 - val_loss: 65375.8398\n",
      "Epoch 147/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 10706.6104 - val_loss: 65207.4609\n",
      "Epoch 148/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 11206.0918 - val_loss: 65014.1523\n",
      "Epoch 149/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 10250.7188 - val_loss: 64850.6758\n",
      "Epoch 150/1000\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 9506.6904 - val_loss: 64731.5977\n",
      "Epoch 151/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 10734.3555 - val_loss: 64657.7852\n",
      "Epoch 152/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 9772.0918 - val_loss: 64594.2656\n",
      "Epoch 153/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 10160.6201 - val_loss: 64567.5000\n",
      "Epoch 154/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 9866.6221 - val_loss: 64536.0000\n",
      "Epoch 155/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 10899.4209 - val_loss: 64554.5391\n",
      "Epoch 156/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 10550.9199 - val_loss: 64625.3359\n",
      "Epoch 157/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 9954.8262 - val_loss: 64735.6641\n",
      "Epoch 158/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 9950.8350 - val_loss: 64829.8125\n",
      "Epoch 159/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 10147.2197 - val_loss: 64903.5664\n",
      "Epoch 160/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 10113.2480 - val_loss: 64939.6875\n",
      "Epoch 161/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 10269.5850 - val_loss: 64930.2383\n",
      "Epoch 162/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 10759.6973 - val_loss: 64914.8984\n",
      "Epoch 163/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 9467.7832 - val_loss: 64959.7344\n",
      "Epoch 164/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 10188.6973 - val_loss: 65034.5039\n",
      "Epoch 165/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 9879.0986 - val_loss: 65130.8984\n",
      "Epoch 166/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 10429.0117 - val_loss: 65250.8086\n",
      "Epoch 167/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 10954.2861 - val_loss: 65372.3281\n",
      "Epoch 168/1000\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 9632.6309 - val_loss: 65500.6016\n",
      "Epoch 169/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 10887.8867 - val_loss: 65614.7500\n",
      "Epoch 170/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 10113.5957 - val_loss: 65703.2969\n",
      "Epoch 171/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 9161.5625 - val_loss: 65768.2578\n",
      "Epoch 172/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 10520.2402 - val_loss: 65823.1797\n",
      "Epoch 173/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 9663.3066 - val_loss: 65860.7031\n",
      "Epoch 174/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 10104.2285 - val_loss: 65930.0938\n",
      "Epoch 175/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 10322.7412 - val_loss: 66010.7031\n",
      "Epoch 176/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 9339.7617 - val_loss: 66062.7812\n",
      "Epoch 177/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 10142.5791 - val_loss: 66113.4453\n",
      "Epoch 178/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 10212.4707 - val_loss: 66176.5391\n",
      "Epoch 179/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 9920.2373 - val_loss: 66210.5312\n",
      "Epoch 180/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 9983.5918 - val_loss: 66171.6484\n",
      "Epoch 181/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 9473.3145 - val_loss: 66126.7578\n",
      "Epoch 182/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 10699.8008 - val_loss: 66090.0859\n",
      "Epoch 183/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 10417.1855 - val_loss: 66031.9453\n",
      "Epoch 184/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 9516.9189 - val_loss: 65973.0000\n",
      "Epoch 185/1000\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 9517.5137 - val_loss: 65868.6016\n",
      "Epoch 186/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 8918.5625 - val_loss: 65753.1953\n",
      "Epoch 187/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 9652.0225 - val_loss: 65623.6484\n",
      "Epoch 188/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 10279.4619 - val_loss: 65560.4766\n",
      "Epoch 189/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 11056.1094 - val_loss: 65521.8984\n",
      "Epoch 190/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 9772.5820 - val_loss: 65492.1250\n",
      "Epoch 191/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 10618.3848 - val_loss: 65468.4531\n",
      "Epoch 192/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 10066.9072 - val_loss: 65460.5664\n",
      "Epoch 193/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 9789.9873 - val_loss: 65440.2969\n",
      "Epoch 194/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 10839.0576 - val_loss: 65420.4648\n",
      "Epoch 195/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 9888.7012 - val_loss: 65392.2461\n",
      "Epoch 196/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 10103.8721 - val_loss: 65372.8281\n",
      "Epoch 197/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 9797.0352 - val_loss: 65332.6484\n",
      "Epoch 198/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 10639.5918 - val_loss: 65324.9336\n",
      "Epoch 199/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 9500.9609 - val_loss: 65323.8477\n",
      "Epoch 200/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 10471.3145 - val_loss: 65331.3398\n",
      "Epoch 201/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 10613.5449 - val_loss: 65316.3164\n",
      "Epoch 202/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 9869.0195 - val_loss: 65337.2383\n",
      "Epoch 203/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 9763.9648 - val_loss: 65375.9766\n",
      "Epoch 204/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 9587.1162 - val_loss: 65400.5664\n",
      "Epoch 205/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 10831.0674 - val_loss: 65456.2969\n",
      "Epoch 206/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 9814.2695 - val_loss: 65490.6484\n",
      "Epoch 207/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 9202.2412 - val_loss: 65534.6602\n",
      "Epoch 208/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 9970.8721 - val_loss: 65587.4844\n",
      "Epoch 209/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 9971.3291 - val_loss: 65609.3594\n",
      "Epoch 210/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 10375.5889 - val_loss: 65591.1719\n",
      "Epoch 211/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 9770.0674 - val_loss: 65545.6953\n",
      "Epoch 212/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 8879.8936 - val_loss: 65551.4062\n",
      "Epoch 213/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 10364.3906 - val_loss: 65606.3281\n",
      "Epoch 214/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 10780.9316 - val_loss: 65662.5312\n",
      "Epoch 215/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 10347.3555 - val_loss: 65656.7500\n",
      "Epoch 216/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 10242.1865 - val_loss: 65661.3203\n",
      "Epoch 217/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 10537.3662 - val_loss: 65685.9766\n",
      "Epoch 218/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 9549.2822 - val_loss: 65666.8516\n",
      "Epoch 219/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 9766.1094 - val_loss: 65559.8750\n",
      "Epoch 220/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 9293.2383 - val_loss: 65425.5586\n",
      "Epoch 221/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 9838.4443 - val_loss: 65366.0664\n",
      "Epoch 222/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 10569.5742 - val_loss: 65397.7734\n",
      "Epoch 223/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 10137.5029 - val_loss: 65469.2500\n",
      "Epoch 224/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 9843.7070 - val_loss: 65566.8047\n",
      "Epoch 225/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 9637.5762 - val_loss: 65651.9219\n",
      "Epoch 226/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 11088.0283 - val_loss: 65743.2422\n",
      "Epoch 227/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 10473.1895 - val_loss: 65833.2578\n",
      "Epoch 228/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 10187.8740 - val_loss: 65935.9297\n",
      "Epoch 229/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 10101.8574 - val_loss: 66015.4688\n",
      "Epoch 230/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 10429.2412 - val_loss: 66088.7422\n",
      "Epoch 231/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 9109.6475 - val_loss: 66130.6562\n",
      "Epoch 232/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 10538.4678 - val_loss: 66195.5391\n",
      "Epoch 233/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 10141.2559 - val_loss: 66281.4453\n",
      "Epoch 234/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 10284.6367 - val_loss: 66360.4766\n",
      "Epoch 235/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 10116.8281 - val_loss: 66377.2734\n",
      "Epoch 236/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 10601.7256 - val_loss: 66355.9766\n",
      "Epoch 237/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 10100.4707 - val_loss: 66362.1797\n",
      "Epoch 238/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 9834.6201 - val_loss: 66355.4766\n",
      "Epoch 239/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 9858.6016 - val_loss: 66357.3672\n",
      "Epoch 240/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 9559.4473 - val_loss: 66366.3828\n",
      "Epoch 241/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 10380.5850 - val_loss: 66400.1875\n",
      "Epoch 242/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 9667.1768 - val_loss: 66433.3438\n",
      "Epoch 243/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 9089.6875 - val_loss: 66427.7422\n",
      "Epoch 244/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 11017.6387 - val_loss: 66460.1406\n",
      "Epoch 245/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 9568.3730 - val_loss: 66467.0078\n",
      "Epoch 246/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 9781.1279 - val_loss: 66427.0234\n",
      "Epoch 247/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 10489.5869 - val_loss: 66363.0547\n",
      "Epoch 248/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 10629.3008 - val_loss: 66208.1484\n",
      "Epoch 249/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 9683.8232 - val_loss: 65988.2891\n",
      "Epoch 250/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 9512.3721 - val_loss: 65763.7891\n",
      "Epoch 251/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 9088.0869 - val_loss: 65468.9492\n",
      "Epoch 252/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 9913.5107 - val_loss: 65145.2383\n",
      "Epoch 253/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 10308.9150 - val_loss: 64883.3984\n",
      "Epoch 254/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 10263.8379 - val_loss: 64651.1719\n",
      "Epoch 255/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 9069.0342 - val_loss: 64430.9023\n",
      "Epoch 256/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 9675.5498 - val_loss: 64285.3984\n",
      "Epoch 257/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 11075.0430 - val_loss: 64198.1992\n",
      "Epoch 258/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 9950.6055 - val_loss: 64107.4414\n",
      "Epoch 259/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 10518.0225 - val_loss: 63977.4648\n",
      "Epoch 260/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 9342.1016 - val_loss: 63954.0000\n",
      "Epoch 261/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 9473.5352 - val_loss: 64015.2617\n",
      "Epoch 262/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 9548.2617 - val_loss: 64083.4023\n",
      "Epoch 263/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 9955.5459 - val_loss: 64110.1367\n",
      "Epoch 264/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 10132.3018 - val_loss: 64114.1406\n",
      "Epoch 265/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 10039.1816 - val_loss: 64095.2031\n",
      "Epoch 266/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 9335.9014 - val_loss: 64019.0625\n",
      "Epoch 267/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 9404.8291 - val_loss: 63985.2031\n",
      "Epoch 268/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 9329.9756 - val_loss: 64013.7852\n",
      "Epoch 269/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 9885.9365 - val_loss: 64085.0586\n",
      "Epoch 270/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 10057.2305 - val_loss: 64178.5273\n",
      "Epoch 271/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 9846.3398 - val_loss: 64308.4883\n",
      "Epoch 272/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 9486.0850 - val_loss: 64435.2656\n",
      "Epoch 273/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 9254.1865 - val_loss: 64566.6836\n",
      "Epoch 274/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 10237.8945 - val_loss: 64707.8867\n",
      "Epoch 275/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 9774.1035 - val_loss: 64826.3242\n",
      "Epoch 276/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 9965.3418 - val_loss: 64994.8398\n",
      "Epoch 277/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 11249.0439 - val_loss: 65190.6602\n",
      "Epoch 278/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 9634.8975 - val_loss: 65368.2852\n",
      "Epoch 279/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 9672.6738 - val_loss: 65506.4219\n",
      "Epoch 280/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 9383.0605 - val_loss: 65678.4062\n",
      "Epoch 281/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 9847.1787 - val_loss: 65800.1250\n",
      "Epoch 282/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 9874.3262 - val_loss: 65820.7578\n",
      "Epoch 283/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 10391.5049 - val_loss: 65853.4688\n",
      "Epoch 284/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 11213.7295 - val_loss: 65924.4766\n",
      "Epoch 285/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 9314.9648 - val_loss: 65997.7578\n",
      "Epoch 286/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 10350.2148 - val_loss: 66032.1172\n",
      "Epoch 287/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 10322.3555 - val_loss: 65996.3672\n",
      "Epoch 288/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 11160.5645 - val_loss: 65917.3672\n",
      "Epoch 289/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 10480.9502 - val_loss: 65841.6641\n",
      "Epoch 290/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 10237.8838 - val_loss: 65749.6719\n",
      "Epoch 291/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 10092.1855 - val_loss: 65705.4766\n",
      "Epoch 292/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 11212.9287 - val_loss: 65698.7031\n",
      "Epoch 293/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 10081.5469 - val_loss: 65711.2031\n",
      "Epoch 294/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 9795.8613 - val_loss: 65682.8984\n",
      "Epoch 295/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 9818.4902 - val_loss: 65701.6250\n",
      "Epoch 296/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 11332.7998 - val_loss: 65766.3828\n",
      "Epoch 297/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 10753.4014 - val_loss: 65774.8203\n",
      "Epoch 298/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 10429.4316 - val_loss: 65769.4688\n",
      "Epoch 299/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 10027.2852 - val_loss: 65779.9297\n",
      "Epoch 300/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 11058.2441 - val_loss: 65782.0859\n",
      "Epoch 301/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 10936.8379 - val_loss: 65788.5547\n",
      "Epoch 302/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 11222.1436 - val_loss: 65775.7188\n",
      "Epoch 303/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 10064.4834 - val_loss: 65809.8203\n",
      "Epoch 304/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 9539.0400 - val_loss: 65863.8672\n",
      "Epoch 305/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 9198.7939 - val_loss: 65992.3203\n",
      "Epoch 306/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 9960.5303 - val_loss: 66110.4688\n",
      "Epoch 307/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 10234.9326 - val_loss: 66094.6172\n",
      "Epoch 308/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 9940.2334 - val_loss: 66043.7188\n",
      "Epoch 309/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 11100.0312 - val_loss: 66068.5547\n",
      "Epoch 310/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 10518.1689 - val_loss: 66146.4062\n",
      "Epoch 311/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 10134.7246 - val_loss: 66262.6172\n",
      "Epoch 312/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 10104.7236 - val_loss: 66339.1328\n",
      "Epoch 313/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 9975.8613 - val_loss: 66313.4297\n",
      "Epoch 314/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 10862.4209 - val_loss: 66243.4062\n",
      "Epoch 315/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 10406.0684 - val_loss: 66226.1172\n",
      "Epoch 316/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 10142.5283 - val_loss: 66198.6953\n",
      "Epoch 317/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 10240.4844 - val_loss: 66172.4219\n",
      "Epoch 318/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 9943.0791 - val_loss: 66138.4062\n",
      "Epoch 319/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 9821.6221 - val_loss: 66103.5234\n",
      "Epoch 320/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 10773.1230 - val_loss: 66136.7578\n",
      "Epoch 321/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 10354.9688 - val_loss: 66185.3984\n",
      "Epoch 322/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 9947.6084 - val_loss: 66260.9219\n",
      "Epoch 323/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 11313.5576 - val_loss: 66322.8125\n",
      "Epoch 324/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 10540.1895 - val_loss: 66319.4922\n",
      "Epoch 325/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 10238.3672 - val_loss: 66320.5859\n",
      "Epoch 326/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 9617.7412 - val_loss: 66330.2422\n",
      "Epoch 327/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 10334.7402 - val_loss: 66299.8750\n",
      "Epoch 328/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 10068.4492 - val_loss: 66225.2188\n",
      "Epoch 329/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 9944.6992 - val_loss: 66195.3203\n",
      "Epoch 330/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 9141.8066 - val_loss: 66200.2578\n",
      "Epoch 331/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 10377.1299 - val_loss: 66186.4297\n",
      "Epoch 332/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 9918.0654 - val_loss: 66172.9297\n",
      "Epoch 333/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 9487.7949 - val_loss: 66201.0312\n",
      "Epoch 334/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 10153.3486 - val_loss: 66207.1484\n",
      "Epoch 335/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 10282.7197 - val_loss: 66143.6562\n",
      "Epoch 336/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 9946.4746 - val_loss: 66126.6328\n",
      "Epoch 337/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 9387.3672 - val_loss: 66122.5547\n",
      "Epoch 338/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 9229.6465 - val_loss: 66084.4141\n",
      "Epoch 339/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 10553.2256 - val_loss: 66027.2188\n",
      "Epoch 340/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 11247.6133 - val_loss: 66025.0859\n",
      "Epoch 341/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 10197.5713 - val_loss: 66035.4062\n",
      "Epoch 342/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 10575.4727 - val_loss: 66123.3984\n",
      "Epoch 343/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 10176.9707 - val_loss: 66185.6797\n",
      "Epoch 344/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 9257.7539 - val_loss: 66224.4922\n",
      "Epoch 345/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 10871.8994 - val_loss: 66226.0000\n",
      "Epoch 346/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 10285.6230 - val_loss: 66159.7578\n",
      "Epoch 347/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 9982.7617 - val_loss: 66170.9219\n",
      "Epoch 348/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 10674.1133 - val_loss: 66215.6250\n",
      "Epoch 349/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 9704.4395 - val_loss: 66211.9844\n",
      "Epoch 350/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 9992.4316 - val_loss: 66231.4453\n",
      "Epoch 351/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 9702.7773 - val_loss: 66344.5547\n",
      "Epoch 352/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 10217.8877 - val_loss: 66463.9844\n",
      "Epoch 353/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 10225.6406 - val_loss: 66528.5469\n",
      "Epoch 354/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 9814.0381 - val_loss: 66600.9141\n",
      "Epoch 355/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 10267.8838 - val_loss: 66692.1172\n",
      "Epoch 356/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 10200.1855 - val_loss: 66804.3672\n",
      "Epoch 357/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 10680.1357 - val_loss: 66896.8281\n",
      "Epoch 358/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 9804.4229 - val_loss: 66931.2734\n",
      "Epoch 359/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 10311.0576 - val_loss: 66980.7500\n",
      "Epoch 360/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 10211.8008 - val_loss: 66991.1328\n",
      "Epoch 361/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 10387.5801 - val_loss: 67005.5938\n",
      "Epoch 362/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 10468.3945 - val_loss: 67075.1250\n",
      "Epoch 363/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 10909.4678 - val_loss: 67144.8438\n",
      "Epoch 364/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 9819.5020 - val_loss: 67234.5234\n",
      "Epoch 365/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 10515.7539 - val_loss: 67301.0859\n",
      "Epoch 366/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 10840.8535 - val_loss: 67389.6328\n",
      "Epoch 367/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 10627.4775 - val_loss: 67457.3203\n",
      "Epoch 368/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 10394.8311 - val_loss: 67489.1250\n",
      "Epoch 369/1000\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 9791.2207 - val_loss: 67512.6172\n",
      "Epoch 370/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 9858.6680 - val_loss: 67518.7422\n",
      "Epoch 371/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 10852.1934 - val_loss: 67531.8594\n",
      "Epoch 372/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 11734.5508 - val_loss: 67534.9531\n",
      "Epoch 373/1000\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 9161.4531 - val_loss: 67477.8203\n",
      "Epoch 374/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 9767.5020 - val_loss: 67403.7500\n",
      "Epoch 375/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 9387.9619 - val_loss: 67370.3438\n",
      "Epoch 376/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 9966.5137 - val_loss: 67405.9766\n",
      "Epoch 377/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 10056.5439 - val_loss: 67464.9453\n",
      "Epoch 378/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 9300.1953 - val_loss: 67540.4219\n",
      "Epoch 379/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 10373.7510 - val_loss: 67594.0781\n",
      "Epoch 380/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 10760.2881 - val_loss: 67634.7969\n",
      "Epoch 381/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 10056.4102 - val_loss: 67694.9062\n",
      "Epoch 382/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 10043.2383 - val_loss: 67743.2266\n",
      "Epoch 383/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 10378.5713 - val_loss: 67718.5312\n",
      "Epoch 384/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 10793.3018 - val_loss: 67703.1875\n",
      "Epoch 385/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 10658.6650 - val_loss: 67707.1797\n",
      "Epoch 386/1000\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 10659.6035 - val_loss: 67678.4062\n",
      "Epoch 387/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 10615.0244 - val_loss: 67618.6797\n",
      "Epoch 388/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 9557.3672 - val_loss: 67519.2578\n",
      "Epoch 389/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 9842.1240 - val_loss: 67309.8984\n",
      "Epoch 390/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 9634.2012 - val_loss: 67115.1562\n",
      "Epoch 391/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 10611.5332 - val_loss: 66960.3516\n",
      "Epoch 392/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 9436.0908 - val_loss: 66794.6953\n",
      "Epoch 393/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 10380.9326 - val_loss: 66664.9688\n",
      "Epoch 394/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 9666.3525 - val_loss: 66521.6016\n",
      "Epoch 395/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 9029.4561 - val_loss: 66360.2188\n",
      "Epoch 396/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 10275.7002 - val_loss: 66173.2422\n",
      "Epoch 397/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 10828.8018 - val_loss: 66008.8203\n",
      "Epoch 398/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 10728.8691 - val_loss: 65834.4688\n",
      "Epoch 399/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 9856.7520 - val_loss: 65668.8281\n",
      "Epoch 400/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 10728.0996 - val_loss: 65570.4922\n",
      "Epoch 401/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 10781.1387 - val_loss: 65476.6016\n",
      "Epoch 402/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 10256.7939 - val_loss: 65396.6484\n",
      "Epoch 403/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 10441.1768 - val_loss: 65403.9336\n",
      "Epoch 404/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 9596.8389 - val_loss: 65459.1914\n",
      "Epoch 405/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 11462.6357 - val_loss: 65567.4766\n",
      "Epoch 406/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 9965.1641 - val_loss: 65687.5547\n",
      "Epoch 407/1000\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 9659.8047 - val_loss: 65805.7266\n",
      "Epoch 408/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 10462.4775 - val_loss: 65843.0000\n",
      "Epoch 409/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 9727.9141 - val_loss: 65875.5938\n",
      "Epoch 410/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 11834.0850 - val_loss: 65975.4531\n",
      "Epoch 411/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 10979.0469 - val_loss: 66096.0938\n",
      "Epoch 412/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 11246.9902 - val_loss: 66218.6172\n",
      "Epoch 413/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 10929.8447 - val_loss: 66353.3203\n",
      "Epoch 414/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 10849.0557 - val_loss: 66467.3984\n",
      "Epoch 415/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 10121.5850 - val_loss: 66589.0625\n",
      "Epoch 416/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 9956.6309 - val_loss: 66722.4297\n",
      "Epoch 417/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 11022.2500 - val_loss: 66804.1641\n",
      "Epoch 418/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 9163.2656 - val_loss: 66761.4062\n",
      "Epoch 419/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 9103.5205 - val_loss: 66733.1328\n",
      "Epoch 420/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 9808.0947 - val_loss: 66764.7031\n",
      "Epoch 421/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 9739.2930 - val_loss: 66773.0078\n",
      "Epoch 422/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 10162.5654 - val_loss: 66761.3359\n",
      "Epoch 423/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 9807.3271 - val_loss: 66691.0859\n",
      "Epoch 424/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 10178.4600 - val_loss: 66657.7188\n",
      "Epoch 425/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 10422.4658 - val_loss: 66647.6484\n",
      "Epoch 426/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 10356.8125 - val_loss: 66571.6172\n",
      "Epoch 427/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 9608.0225 - val_loss: 66429.3828\n",
      "Epoch 428/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 10900.1748 - val_loss: 66331.0156\n",
      "Epoch 429/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 10507.8213 - val_loss: 66254.0547\n",
      "Epoch 430/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 10584.0498 - val_loss: 66124.1328\n",
      "Epoch 431/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 10745.3145 - val_loss: 66015.3516\n",
      "Epoch 432/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 11524.4150 - val_loss: 65986.4219\n",
      "Epoch 433/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 9893.0049 - val_loss: 66042.7031\n",
      "Epoch 434/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 10330.5840 - val_loss: 66088.8516\n",
      "Epoch 435/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 10232.6758 - val_loss: 66103.3516\n",
      "Epoch 436/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 10357.8037 - val_loss: 66089.2734\n",
      "Epoch 437/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 10488.9492 - val_loss: 66117.4531\n",
      "Epoch 438/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 10549.6963 - val_loss: 66187.0078\n",
      "Epoch 439/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 10527.8867 - val_loss: 66289.3516\n",
      "Epoch 440/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 10271.3389 - val_loss: 66326.3203\n",
      "Epoch 441/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 10083.7412 - val_loss: 66350.6328\n",
      "Epoch 442/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 9900.1338 - val_loss: 66340.1172\n",
      "Epoch 443/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 11519.5234 - val_loss: 66246.0938\n",
      "Epoch 444/1000\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 9890.3564 - val_loss: 66093.6172\n",
      "Epoch 445/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 10591.9092 - val_loss: 65913.5547\n",
      "Epoch 446/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 10297.8682 - val_loss: 65782.7031\n",
      "Epoch 447/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 9710.9951 - val_loss: 65657.1328\n",
      "Epoch 448/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 10023.2549 - val_loss: 65495.8984\n",
      "Epoch 449/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 10018.9883 - val_loss: 65313.3906\n",
      "Epoch 450/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 10632.9775 - val_loss: 65169.0859\n",
      "Epoch 451/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 10948.4971 - val_loss: 65071.1094\n",
      "Epoch 452/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 9939.2500 - val_loss: 64960.9766\n",
      "Epoch 453/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 9683.3975 - val_loss: 64928.1484\n",
      "Epoch 454/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 9748.4512 - val_loss: 64945.1289\n",
      "Epoch 455/1000\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 10062.2188 - val_loss: 65004.8633\n",
      "Epoch 456/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 10897.5215 - val_loss: 65091.3398\n",
      "Epoch 457/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 10289.3594 - val_loss: 65182.7969\n",
      "Epoch 458/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 10761.9092 - val_loss: 65263.2617\n",
      "Epoch 459/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 10102.6738 - val_loss: 65365.1523\n",
      "Epoch 460/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 9697.5293 - val_loss: 65504.5586\n",
      "Epoch 461/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 11303.4814 - val_loss: 65702.1172\n",
      "Epoch 462/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 10157.3457 - val_loss: 65892.2812\n",
      "Epoch 463/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 10607.1387 - val_loss: 65995.3438\n",
      "Epoch 464/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 10417.1875 - val_loss: 66059.4453\n",
      "Epoch 465/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 9756.9814 - val_loss: 66082.6953\n",
      "Epoch 466/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 9673.8145 - val_loss: 66069.8984\n",
      "Epoch 467/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 9758.1270 - val_loss: 66067.8281\n",
      "Epoch 468/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 10702.0615 - val_loss: 66098.1953\n",
      "Epoch 469/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 9975.3311 - val_loss: 66123.9141\n",
      "Epoch 470/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 10108.1172 - val_loss: 66209.6719\n",
      "Epoch 471/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 10573.7139 - val_loss: 66308.0547\n",
      "Epoch 472/1000\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 9783.5361 - val_loss: 66323.2188\n",
      "Epoch 473/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 10423.0820 - val_loss: 66401.2266\n",
      "Epoch 474/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 10225.0820 - val_loss: 66506.2578\n",
      "Epoch 475/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 10270.7471 - val_loss: 66571.2734\n",
      "Epoch 476/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 9348.9463 - val_loss: 66538.7500\n",
      "Epoch 477/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 10197.6650 - val_loss: 66545.3438\n",
      "Epoch 478/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 10683.0342 - val_loss: 66629.5938\n",
      "Epoch 479/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 9540.2676 - val_loss: 66643.0156\n",
      "Epoch 480/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 9654.0049 - val_loss: 66526.1484\n",
      "Epoch 481/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 10150.4463 - val_loss: 66381.7031\n",
      "Epoch 482/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 9815.7197 - val_loss: 66235.8828\n",
      "Epoch 483/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 10965.0781 - val_loss: 66146.2422\n",
      "Epoch 484/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 10067.8125 - val_loss: 66094.2188\n",
      "Epoch 485/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 9918.0322 - val_loss: 66015.1719\n",
      "Epoch 486/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 10593.1787 - val_loss: 66050.6250\n",
      "Epoch 487/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 10908.2920 - val_loss: 66185.0781\n",
      "Epoch 488/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 10223.0625 - val_loss: 66328.6797\n",
      "Epoch 489/1000\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 10471.1211 - val_loss: 66518.1719\n",
      "Epoch 490/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 10470.1934 - val_loss: 66694.2422\n",
      "Epoch 491/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 9804.9570 - val_loss: 66800.3828\n",
      "Epoch 492/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 10084.3721 - val_loss: 66835.6562\n",
      "Epoch 493/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 10914.0762 - val_loss: 66837.2500\n",
      "Epoch 494/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 10067.5068 - val_loss: 66836.3516\n",
      "Epoch 495/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 9950.8525 - val_loss: 66871.2969\n",
      "Epoch 496/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 9731.9951 - val_loss: 66909.9219\n",
      "Epoch 497/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 10235.8184 - val_loss: 66892.7500\n",
      "Epoch 498/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 10852.2588 - val_loss: 66843.4297\n",
      "Epoch 499/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 9877.6621 - val_loss: 66758.4766\n",
      "Epoch 500/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 10574.6240 - val_loss: 66719.2422\n",
      "Epoch 501/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 9863.4014 - val_loss: 66713.2188\n",
      "Epoch 502/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 9804.2236 - val_loss: 66687.4297\n",
      "Epoch 503/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 10000.6953 - val_loss: 66713.9297\n",
      "Epoch 504/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 10447.0850 - val_loss: 66784.8203\n",
      "Epoch 505/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 11137.2354 - val_loss: 66890.5234\n",
      "Epoch 506/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 10879.3008 - val_loss: 67005.1016\n",
      "Epoch 507/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 9365.1162 - val_loss: 67015.4531\n",
      "Epoch 508/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 9205.0654 - val_loss: 66924.9844\n",
      "Epoch 509/1000\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 9578.9570 - val_loss: 66857.4531\n",
      "Epoch 510/1000\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 9908.9639 - val_loss: 66782.3984\n",
      "Epoch 511/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 10439.4600 - val_loss: 66658.0391\n",
      "Epoch 512/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 10245.2188 - val_loss: 66555.1484\n",
      "Epoch 513/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 10268.6172 - val_loss: 66530.0312\n",
      "Epoch 514/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 10168.8340 - val_loss: 66565.0469\n",
      "Epoch 515/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 10391.0410 - val_loss: 66584.3438\n",
      "Epoch 516/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 9292.7705 - val_loss: 66529.3672\n",
      "Epoch 517/1000\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 10090.5410 - val_loss: 66486.5000\n",
      "Epoch 518/1000\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 11195.0596 - val_loss: 66469.6328\n",
      "Epoch 519/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 10515.1582 - val_loss: 66504.8125\n",
      "Epoch 520/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 9688.2432 - val_loss: 66536.1016\n",
      "Epoch 521/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 10260.6758 - val_loss: 66550.7812\n",
      "Epoch 522/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 10861.3633 - val_loss: 66450.4453\n",
      "Epoch 523/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 10323.9180 - val_loss: 66332.8438\n",
      "Epoch 524/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 9390.9941 - val_loss: 66257.8125\n",
      "Epoch 525/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 9668.9043 - val_loss: 66174.3750\n",
      "Epoch 526/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 10514.2480 - val_loss: 66048.7734\n",
      "Epoch 527/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 9506.9707 - val_loss: 65919.9766\n",
      "Epoch 528/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 10081.5020 - val_loss: 65824.5938\n",
      "Epoch 529/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 10352.8281 - val_loss: 65749.8516\n",
      "Epoch 530/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 9981.3467 - val_loss: 65664.9297\n",
      "Epoch 531/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 9834.0293 - val_loss: 65506.3594\n",
      "Epoch 532/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 9304.1924 - val_loss: 65340.2500\n",
      "Epoch 533/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 10767.1885 - val_loss: 65205.2148\n",
      "Epoch 534/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 10026.0068 - val_loss: 65109.9414\n",
      "Epoch 535/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 10234.5107 - val_loss: 65071.7500\n",
      "Epoch 536/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 10384.0303 - val_loss: 65061.4102\n",
      "Epoch 537/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 9994.0742 - val_loss: 65019.1641\n",
      "Epoch 538/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 10432.0020 - val_loss: 65021.5664\n",
      "Epoch 539/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 11013.9150 - val_loss: 65007.9766\n",
      "Epoch 540/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 9452.3232 - val_loss: 64953.8086\n",
      "Epoch 541/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 9296.2656 - val_loss: 64814.6719\n",
      "Epoch 542/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 10360.1191 - val_loss: 64698.0586\n",
      "Epoch 543/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 10522.6367 - val_loss: 64641.9766\n",
      "Epoch 544/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 9842.2139 - val_loss: 64554.6484\n",
      "Epoch 545/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 9769.6064 - val_loss: 64476.8359\n",
      "Epoch 546/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 9366.9395 - val_loss: 64425.6016\n",
      "Epoch 547/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 10165.8271 - val_loss: 64365.4414\n",
      "Epoch 548/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 9794.7158 - val_loss: 64332.8516\n",
      "Epoch 549/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 10049.2969 - val_loss: 64358.5977\n",
      "Epoch 550/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 10245.3594 - val_loss: 64360.1719\n",
      "Epoch 551/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 10193.1553 - val_loss: 64229.6914\n",
      "Epoch 552/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 10120.7236 - val_loss: 64085.0000\n",
      "Epoch 553/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 10812.4131 - val_loss: 64055.5234\n",
      "Epoch 554/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 9410.5195 - val_loss: 64044.7773\n",
      "Epoch 555/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 9805.6758 - val_loss: 64042.8086\n",
      "Epoch 556/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 11187.8701 - val_loss: 64085.9414\n",
      "Epoch 557/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 8997.6650 - val_loss: 64065.9531\n",
      "Epoch 558/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 9478.1387 - val_loss: 64035.3086\n",
      "Epoch 559/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 10430.4424 - val_loss: 64019.7109\n",
      "Epoch 560/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 10170.3623 - val_loss: 63990.5742\n",
      "Epoch 561/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 9373.5918 - val_loss: 63912.0469\n",
      "Epoch 562/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 10610.6445 - val_loss: 63779.0117\n",
      "Epoch 563/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 10335.7910 - val_loss: 63730.8242\n",
      "Epoch 564/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 11366.3672 - val_loss: 63771.8984\n",
      "Epoch 565/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 10131.1064 - val_loss: 63841.7500\n",
      "Epoch 566/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 10541.6592 - val_loss: 63878.3516\n",
      "Epoch 567/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 10660.6602 - val_loss: 63905.8594\n",
      "Epoch 568/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 9507.2070 - val_loss: 63871.8398\n",
      "Epoch 569/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 10267.7246 - val_loss: 63848.7891\n",
      "Epoch 570/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 10295.9102 - val_loss: 63796.3867\n",
      "Epoch 571/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 9477.7754 - val_loss: 63723.2969\n",
      "Epoch 572/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 10569.0410 - val_loss: 63686.3750\n",
      "Epoch 573/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 11025.6299 - val_loss: 63715.3398\n",
      "Epoch 574/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 9848.2139 - val_loss: 63834.3867\n",
      "Epoch 575/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 9825.4736 - val_loss: 64061.2969\n",
      "Epoch 576/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 10217.5254 - val_loss: 64307.3789\n",
      "Epoch 577/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 9629.1797 - val_loss: 64490.7617\n",
      "Epoch 578/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 9763.6094 - val_loss: 64599.7227\n",
      "Epoch 579/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 10315.5723 - val_loss: 64761.4414\n",
      "Epoch 580/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 9467.1426 - val_loss: 64951.1719\n",
      "Epoch 581/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 9675.1328 - val_loss: 65176.8750\n",
      "Epoch 582/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 10224.2393 - val_loss: 65383.0117\n",
      "Epoch 583/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 10269.0254 - val_loss: 65508.3711\n",
      "Epoch 584/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 10424.9150 - val_loss: 65602.6797\n",
      "Epoch 585/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 10042.9863 - val_loss: 65751.7500\n",
      "Epoch 586/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 10051.1416 - val_loss: 65862.6016\n",
      "Epoch 587/1000\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 10800.6328 - val_loss: 65970.2188\n",
      "Epoch 588/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 9887.9199 - val_loss: 66088.7422\n",
      "Epoch 589/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 9666.3584 - val_loss: 66209.8672\n",
      "Epoch 590/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 9936.4980 - val_loss: 66331.0391\n",
      "Epoch 591/1000\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 10515.2158 - val_loss: 66373.3047\n",
      "Epoch 592/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 9920.5762 - val_loss: 66282.3828\n",
      "Epoch 593/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 10392.8096 - val_loss: 66267.7266\n",
      "Epoch 594/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 10450.0449 - val_loss: 66284.2109\n",
      "Epoch 595/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 9756.8975 - val_loss: 66180.6875\n",
      "Epoch 596/1000\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 10019.5879 - val_loss: 65973.5469\n",
      "Epoch 597/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 10532.9219 - val_loss: 65811.8359\n",
      "Epoch 598/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 10273.0059 - val_loss: 65624.1953\n",
      "Epoch 599/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 10574.1367 - val_loss: 65353.4844\n",
      "Epoch 600/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 10286.5400 - val_loss: 65072.8906\n",
      "Epoch 601/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 10507.7822 - val_loss: 64808.5586\n",
      "Epoch 602/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 9476.8613 - val_loss: 64611.5273\n",
      "Epoch 603/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 10148.8877 - val_loss: 64477.5586\n",
      "Epoch 604/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 9870.8037 - val_loss: 64354.1719\n",
      "Epoch 605/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 9345.4531 - val_loss: 64199.5898\n",
      "Epoch 606/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 9228.9189 - val_loss: 64035.6133\n",
      "Epoch 607/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 9846.2168 - val_loss: 63859.5664\n",
      "Epoch 608/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 9181.8184 - val_loss: 63681.2656\n",
      "Epoch 609/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 10338.5303 - val_loss: 63558.7656\n",
      "Epoch 610/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 10564.4355 - val_loss: 63473.0352\n",
      "Epoch 611/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 9440.6484 - val_loss: 63492.1875\n",
      "Epoch 612/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 10257.1982 - val_loss: 63600.0391\n",
      "Epoch 613/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 11637.2607 - val_loss: 63757.2148\n",
      "Epoch 614/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 10271.7959 - val_loss: 63884.9336\n",
      "Epoch 615/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 10131.0781 - val_loss: 64047.8398\n",
      "Epoch 616/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 9845.5303 - val_loss: 64159.9258\n",
      "Epoch 617/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 10202.2246 - val_loss: 64252.0508\n",
      "Epoch 618/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 11167.2969 - val_loss: 64388.2109\n",
      "Epoch 619/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 9801.4521 - val_loss: 64565.0664\n",
      "Epoch 620/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 8950.4424 - val_loss: 64785.1133\n",
      "Epoch 621/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 10144.6201 - val_loss: 64986.4531\n",
      "Epoch 622/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 9823.7139 - val_loss: 65123.4258\n",
      "Epoch 623/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 11594.6055 - val_loss: 65301.9023\n",
      "Epoch 624/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 11009.0410 - val_loss: 65529.5117\n",
      "Epoch 625/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 11057.2744 - val_loss: 65759.8281\n",
      "Epoch 626/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 10426.4600 - val_loss: 65962.5547\n",
      "Epoch 627/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 11106.0479 - val_loss: 66189.1953\n",
      "Epoch 628/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 9715.4922 - val_loss: 66429.3438\n",
      "Epoch 629/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 9709.7002 - val_loss: 66586.5078\n",
      "Epoch 630/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 10227.4131 - val_loss: 66683.3047\n",
      "Epoch 631/1000\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 9468.1172 - val_loss: 66747.3281\n",
      "Epoch 632/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 9895.1885 - val_loss: 66836.0703\n",
      "Epoch 633/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 9616.4248 - val_loss: 66933.8828\n",
      "Epoch 634/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 10509.2754 - val_loss: 66985.1875\n",
      "Epoch 635/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 9588.7178 - val_loss: 67011.1875\n",
      "Epoch 636/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 10043.3828 - val_loss: 66963.0312\n",
      "Epoch 637/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 9134.8936 - val_loss: 66892.5547\n",
      "Epoch 638/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 10051.1191 - val_loss: 66867.7578\n",
      "Epoch 639/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 9405.0430 - val_loss: 66820.9062\n",
      "Epoch 640/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 9470.5283 - val_loss: 66733.0234\n",
      "Epoch 641/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 10584.9238 - val_loss: 66645.5781\n",
      "Epoch 642/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 10004.5771 - val_loss: 66583.0938\n",
      "Epoch 643/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 11001.3555 - val_loss: 66431.3047\n",
      "Epoch 644/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 10741.9736 - val_loss: 66313.5938\n",
      "Epoch 645/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 10179.2910 - val_loss: 66197.3906\n",
      "Epoch 646/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 10186.2988 - val_loss: 66063.6562\n",
      "Epoch 647/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 10172.4551 - val_loss: 65942.5859\n",
      "Epoch 648/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 11557.4180 - val_loss: 65862.1016\n",
      "Epoch 649/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 9841.3027 - val_loss: 65855.6094\n",
      "Epoch 650/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 10795.2334 - val_loss: 65811.6328\n",
      "Epoch 651/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 10114.6865 - val_loss: 65688.2188\n",
      "Epoch 652/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 9431.3174 - val_loss: 65512.7891\n",
      "Epoch 653/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 10302.1201 - val_loss: 65375.8516\n",
      "Epoch 654/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 10020.7061 - val_loss: 65345.2383\n",
      "Epoch 655/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 9770.6680 - val_loss: 65387.6836\n",
      "Epoch 656/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 9934.9111 - val_loss: 65431.7031\n",
      "Epoch 657/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 10106.3145 - val_loss: 65432.3086\n",
      "Epoch 658/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 9896.4150 - val_loss: 65488.5391\n",
      "Epoch 659/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 10301.5947 - val_loss: 65600.3672\n",
      "Epoch 660/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 10218.0117 - val_loss: 65752.9453\n",
      "Epoch 661/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 9892.4043 - val_loss: 65906.3672\n",
      "Epoch 662/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 11042.8486 - val_loss: 66021.4844\n",
      "Epoch 663/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 10353.6504 - val_loss: 66059.4922\n",
      "Epoch 664/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 11223.9736 - val_loss: 66051.0234\n",
      "Epoch 665/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 10715.8154 - val_loss: 65972.0234\n",
      "Epoch 666/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 9963.6846 - val_loss: 65936.5312\n",
      "Epoch 667/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 10356.2900 - val_loss: 65896.5703\n",
      "Epoch 668/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 10106.7314 - val_loss: 65838.5312\n",
      "Epoch 669/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 10265.9326 - val_loss: 65783.3828\n",
      "Epoch 670/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 9897.1006 - val_loss: 65813.5234\n",
      "Epoch 671/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 9655.1250 - val_loss: 65913.1562\n",
      "Epoch 672/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 11189.6104 - val_loss: 65998.7812\n",
      "Epoch 673/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 9963.0889 - val_loss: 66082.8047\n",
      "Epoch 674/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 10102.2393 - val_loss: 66164.5312\n",
      "Epoch 675/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 10941.7188 - val_loss: 66190.7578\n",
      "Epoch 676/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 10122.3799 - val_loss: 66117.2188\n",
      "Epoch 677/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 9625.4023 - val_loss: 66035.6484\n",
      "Epoch 678/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 10363.9131 - val_loss: 65914.4297\n",
      "Epoch 679/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 9439.4453 - val_loss: 65754.5703\n",
      "Epoch 680/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 10116.4775 - val_loss: 65692.0625\n",
      "Epoch 681/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 10192.4600 - val_loss: 65716.8281\n",
      "Epoch 682/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 8730.4209 - val_loss: 65698.9609\n",
      "Epoch 683/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 10180.7041 - val_loss: 65623.8828\n",
      "Epoch 684/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 10090.7725 - val_loss: 65464.7266\n",
      "Epoch 685/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 11215.1357 - val_loss: 65399.8633\n",
      "Epoch 686/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 9694.3438 - val_loss: 65440.5352\n",
      "Epoch 687/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 9405.0117 - val_loss: 65515.2852\n",
      "Epoch 688/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 10559.5146 - val_loss: 65545.7500\n",
      "Epoch 689/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 10331.9111 - val_loss: 65547.5938\n",
      "Epoch 690/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 11409.7832 - val_loss: 65632.0078\n",
      "Epoch 691/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 9753.3701 - val_loss: 65714.3438\n",
      "Epoch 692/1000\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 9917.6650 - val_loss: 65742.5625\n",
      "Epoch 693/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 10142.0059 - val_loss: 65710.5078\n",
      "Epoch 694/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 10417.2100 - val_loss: 65642.6094\n",
      "Epoch 695/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 10127.2939 - val_loss: 65608.0312\n",
      "Epoch 696/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 10041.7861 - val_loss: 65537.2422\n",
      "Epoch 697/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 10887.6777 - val_loss: 65352.6367\n",
      "Epoch 698/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 9512.5020 - val_loss: 65176.8398\n",
      "Epoch 699/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 10594.3154 - val_loss: 65083.8984\n",
      "Epoch 700/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 9506.3887 - val_loss: 64966.1641\n",
      "Epoch 701/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 10175.8379 - val_loss: 64818.6602\n",
      "Epoch 702/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 10039.8330 - val_loss: 64747.0898\n",
      "Epoch 703/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 10853.9541 - val_loss: 64710.8867\n",
      "Epoch 704/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 10680.2168 - val_loss: 64667.1602\n",
      "Epoch 705/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 10382.1787 - val_loss: 64587.9336\n",
      "Epoch 706/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 9218.6855 - val_loss: 64515.7891\n",
      "Epoch 707/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 10851.1992 - val_loss: 64558.3125\n",
      "Epoch 708/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 10538.2412 - val_loss: 64698.5742\n",
      "Epoch 709/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 9945.4385 - val_loss: 64856.6016\n",
      "Epoch 710/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 10078.4385 - val_loss: 64946.4531\n",
      "Epoch 711/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 11342.0156 - val_loss: 64998.8750\n",
      "Epoch 712/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 9907.6572 - val_loss: 65073.6484\n",
      "Epoch 713/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 9916.8867 - val_loss: 65164.3984\n",
      "Epoch 714/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 10985.0508 - val_loss: 65266.7500\n",
      "Epoch 715/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 11166.8936 - val_loss: 65357.3594\n",
      "Epoch 716/1000\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 10073.4961 - val_loss: 65510.0586\n",
      "Epoch 717/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 10633.6094 - val_loss: 65711.2578\n",
      "Epoch 718/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 10181.1143 - val_loss: 65849.7969\n",
      "Epoch 719/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 10952.0850 - val_loss: 66039.9219\n",
      "Epoch 720/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 10154.0225 - val_loss: 66256.9297\n",
      "Epoch 721/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 10035.5576 - val_loss: 66468.4688\n",
      "Epoch 722/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 10449.0430 - val_loss: 66697.8203\n",
      "Epoch 723/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 10351.3994 - val_loss: 66833.8047\n",
      "Epoch 724/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 11017.3838 - val_loss: 66912.0078\n",
      "Epoch 725/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 10420.2256 - val_loss: 66960.1797\n",
      "Epoch 726/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 11240.2500 - val_loss: 66957.9922\n",
      "Epoch 727/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 9402.6924 - val_loss: 66986.0859\n",
      "Epoch 728/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 10211.5088 - val_loss: 67024.2422\n",
      "Epoch 729/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 9873.8232 - val_loss: 66930.8750\n",
      "Epoch 730/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 9933.6963 - val_loss: 66721.3203\n",
      "Epoch 731/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 10931.3633 - val_loss: 66549.7031\n",
      "Epoch 732/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 10422.4121 - val_loss: 66343.0469\n",
      "Epoch 733/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 10057.4258 - val_loss: 66165.7812\n",
      "Epoch 734/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 10147.9805 - val_loss: 66069.2734\n",
      "Epoch 735/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 10769.0645 - val_loss: 66024.1484\n",
      "Epoch 736/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 11046.2549 - val_loss: 65983.3047\n",
      "Epoch 737/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 10759.1338 - val_loss: 65936.5156\n",
      "Epoch 738/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 10018.5098 - val_loss: 65896.0703\n",
      "Epoch 739/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 10337.8350 - val_loss: 65909.3672\n",
      "Epoch 740/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 10845.3975 - val_loss: 65865.2422\n",
      "Epoch 741/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 9940.2969 - val_loss: 65824.2734\n",
      "Epoch 742/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 10166.0986 - val_loss: 65852.7109\n",
      "Epoch 743/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 9831.5781 - val_loss: 65912.9922\n",
      "Epoch 744/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 11161.0469 - val_loss: 65995.9922\n",
      "Epoch 745/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 9726.2959 - val_loss: 66013.8203\n",
      "Epoch 746/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 11281.7979 - val_loss: 65868.8828\n",
      "Epoch 747/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 10630.1162 - val_loss: 65779.5938\n",
      "Epoch 748/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 9707.2168 - val_loss: 65717.9297\n",
      "Epoch 749/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 9884.7178 - val_loss: 65671.5234\n",
      "Epoch 750/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 10362.6719 - val_loss: 65667.6328\n",
      "Epoch 751/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 9966.5537 - val_loss: 65611.3672\n",
      "Epoch 752/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 9882.9678 - val_loss: 65537.9219\n",
      "Epoch 753/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 9977.2529 - val_loss: 65491.6367\n",
      "Epoch 754/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 10392.9287 - val_loss: 65428.4883\n",
      "Epoch 755/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 10184.8242 - val_loss: 65375.0742\n",
      "Epoch 756/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 9957.8291 - val_loss: 65370.1836\n",
      "Epoch 757/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 10605.3184 - val_loss: 65346.6016\n",
      "Epoch 758/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 10011.4492 - val_loss: 65320.1758\n",
      "Epoch 759/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 9666.4814 - val_loss: 65291.4336\n",
      "Epoch 760/1000\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 10625.6982 - val_loss: 65301.7656\n",
      "Epoch 761/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 10793.3828 - val_loss: 65318.0781\n",
      "Epoch 762/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 10114.8730 - val_loss: 65361.3398\n",
      "Epoch 763/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 10221.0234 - val_loss: 65430.5859\n",
      "Epoch 764/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 9368.3975 - val_loss: 65535.6523\n",
      "Epoch 765/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 10167.5918 - val_loss: 65620.0312\n",
      "Epoch 766/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 10646.2510 - val_loss: 65666.3047\n",
      "Epoch 767/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 9803.5723 - val_loss: 65753.3438\n",
      "Epoch 768/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 10610.9111 - val_loss: 65891.0234\n",
      "Epoch 769/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 10215.7363 - val_loss: 66069.9062\n",
      "Epoch 770/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 10639.7861 - val_loss: 66209.5938\n",
      "Epoch 771/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 10157.1514 - val_loss: 66221.5625\n",
      "Epoch 772/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 10969.3633 - val_loss: 66193.9297\n",
      "Epoch 773/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 9954.5811 - val_loss: 66248.1172\n",
      "Epoch 774/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 9455.0117 - val_loss: 66249.4453\n",
      "Epoch 775/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 9567.2637 - val_loss: 66205.3828\n",
      "Epoch 776/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 9588.5049 - val_loss: 66178.8672\n",
      "Epoch 777/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 10565.1055 - val_loss: 66201.2031\n",
      "Epoch 778/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 10473.1133 - val_loss: 66219.8203\n",
      "Epoch 779/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 10387.5459 - val_loss: 66268.3750\n",
      "Epoch 780/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 10688.3818 - val_loss: 66301.1484\n",
      "Epoch 781/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 9930.8262 - val_loss: 66312.2031\n",
      "Epoch 782/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 10240.5576 - val_loss: 66323.2891\n",
      "Epoch 783/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 10804.0332 - val_loss: 66354.1953\n",
      "Epoch 784/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 10650.5264 - val_loss: 66479.1406\n",
      "Epoch 785/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 10148.6865 - val_loss: 66633.6250\n",
      "Epoch 786/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 9557.2139 - val_loss: 66742.1484\n",
      "Epoch 787/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 9503.1367 - val_loss: 66814.3203\n",
      "Epoch 788/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 9334.5430 - val_loss: 66890.7031\n",
      "Epoch 789/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 9069.0703 - val_loss: 66901.3203\n",
      "Epoch 790/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 10349.4512 - val_loss: 66874.0312\n",
      "Epoch 791/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 9624.3174 - val_loss: 66817.8906\n",
      "Epoch 792/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 11083.1055 - val_loss: 66842.7656\n",
      "Epoch 793/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 9649.3750 - val_loss: 66912.4062\n",
      "Epoch 794/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 9853.2725 - val_loss: 66947.1562\n",
      "Epoch 795/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 10251.0117 - val_loss: 66904.1406\n",
      "Epoch 796/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 9638.1221 - val_loss: 66817.0938\n",
      "Epoch 797/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 9999.5781 - val_loss: 66661.0234\n",
      "Epoch 798/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 10490.6934 - val_loss: 66497.3281\n",
      "Epoch 799/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 10094.9736 - val_loss: 66400.1875\n",
      "Epoch 800/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 10216.7344 - val_loss: 66324.2266\n",
      "Epoch 801/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 10636.9199 - val_loss: 66334.5547\n",
      "Epoch 802/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 10517.6309 - val_loss: 66371.1094\n",
      "Epoch 803/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 10301.8281 - val_loss: 66387.5000\n",
      "Epoch 804/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 11304.7686 - val_loss: 66528.3828\n",
      "Epoch 805/1000\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 9041.6221 - val_loss: 66668.8516\n",
      "Epoch 806/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 9868.5264 - val_loss: 66718.2734\n",
      "Epoch 807/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 9859.8564 - val_loss: 66681.0625\n",
      "Epoch 808/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 9857.8828 - val_loss: 66581.9531\n",
      "Epoch 809/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 10259.4561 - val_loss: 66467.4609\n",
      "Epoch 810/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 11009.3730 - val_loss: 66396.4688\n",
      "Epoch 811/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 9709.3037 - val_loss: 66375.3750\n",
      "Epoch 812/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 9695.2383 - val_loss: 66333.7578\n",
      "Epoch 813/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 11034.1211 - val_loss: 66262.6250\n",
      "Epoch 814/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 9476.2969 - val_loss: 66167.9297\n",
      "Epoch 815/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 9223.9688 - val_loss: 66082.7578\n",
      "Epoch 816/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 9046.1016 - val_loss: 66007.3828\n",
      "Epoch 817/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 10052.6865 - val_loss: 65854.9453\n",
      "Epoch 818/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 10163.9473 - val_loss: 65763.3047\n",
      "Epoch 819/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 10468.2607 - val_loss: 65683.2188\n",
      "Epoch 820/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 10159.7832 - val_loss: 65596.9766\n",
      "Epoch 821/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 10680.5410 - val_loss: 65575.0312\n",
      "Epoch 822/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 9362.5713 - val_loss: 65641.2188\n",
      "Epoch 823/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 9560.4268 - val_loss: 65693.3516\n",
      "Epoch 824/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 8878.0586 - val_loss: 65669.7734\n",
      "Epoch 825/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 9788.2275 - val_loss: 65638.8984\n",
      "Epoch 826/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 10909.6035 - val_loss: 65584.4844\n",
      "Epoch 827/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 10899.3340 - val_loss: 65522.1914\n",
      "Epoch 828/1000\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 9745.5547 - val_loss: 65483.8594\n",
      "Epoch 829/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 10810.1514 - val_loss: 65489.0664\n",
      "Epoch 830/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 10100.0518 - val_loss: 65598.8203\n",
      "Epoch 831/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 10560.1855 - val_loss: 65731.7891\n",
      "Epoch 832/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 8655.4912 - val_loss: 65816.3906\n",
      "Epoch 833/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 9556.9580 - val_loss: 65921.6484\n",
      "Epoch 834/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 10159.4297 - val_loss: 66052.7578\n",
      "Epoch 835/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 10558.2559 - val_loss: 66233.4453\n",
      "Epoch 836/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 10509.8320 - val_loss: 66355.3281\n",
      "Epoch 837/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 9966.1641 - val_loss: 66339.1484\n",
      "Epoch 838/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 9912.4180 - val_loss: 66309.8672\n",
      "Epoch 839/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 9985.2861 - val_loss: 66205.8516\n",
      "Epoch 840/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 9758.0371 - val_loss: 65990.7969\n",
      "Epoch 841/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 10574.6133 - val_loss: 65777.9453\n",
      "Epoch 842/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 10013.7803 - val_loss: 65678.8984\n",
      "Epoch 843/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 9705.3818 - val_loss: 65610.5547\n",
      "Epoch 844/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 10110.4072 - val_loss: 65605.1328\n",
      "Epoch 845/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 9711.2197 - val_loss: 65563.9688\n",
      "Epoch 846/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 10455.8154 - val_loss: 65594.0547\n",
      "Epoch 847/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 10389.7451 - val_loss: 65673.7500\n",
      "Epoch 848/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 10183.6904 - val_loss: 65768.0156\n",
      "Epoch 849/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 10072.5820 - val_loss: 65847.8828\n",
      "Epoch 850/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 10676.6904 - val_loss: 65986.3828\n",
      "Epoch 851/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 10885.2910 - val_loss: 66120.6172\n",
      "Epoch 852/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 9364.1436 - val_loss: 66326.9219\n",
      "Epoch 853/1000\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 10487.8906 - val_loss: 66524.7578\n",
      "Epoch 854/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 9489.3916 - val_loss: 66624.0703\n",
      "Epoch 855/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 9999.4346 - val_loss: 66654.8828\n",
      "Epoch 856/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 10329.2178 - val_loss: 66589.3828\n",
      "Epoch 857/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 10684.7969 - val_loss: 66532.4062\n",
      "Epoch 858/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 10249.3076 - val_loss: 66485.9375\n",
      "Epoch 859/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 9741.2822 - val_loss: 66477.3984\n",
      "Epoch 860/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 9893.0195 - val_loss: 66435.2031\n",
      "Epoch 861/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 9996.8125 - val_loss: 66416.0391\n",
      "Epoch 862/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 9830.6631 - val_loss: 66423.0000\n",
      "Epoch 863/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 9568.6465 - val_loss: 66467.7812\n",
      "Epoch 864/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 10373.1299 - val_loss: 66492.9922\n",
      "Epoch 865/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 10019.8232 - val_loss: 66455.3359\n",
      "Epoch 866/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 10269.6377 - val_loss: 66351.0391\n",
      "Epoch 867/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 9630.5547 - val_loss: 66299.7578\n",
      "Epoch 868/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 9939.9756 - val_loss: 66221.3906\n",
      "Epoch 869/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 10174.2275 - val_loss: 66122.1797\n",
      "Epoch 870/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 10287.2012 - val_loss: 66052.6094\n",
      "Epoch 871/1000\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 9425.9482 - val_loss: 66065.0781\n",
      "Epoch 872/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 11559.7041 - val_loss: 66161.6719\n",
      "Epoch 873/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 9475.3770 - val_loss: 66218.6094\n",
      "Epoch 874/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 10926.2275 - val_loss: 66220.5234\n",
      "Epoch 875/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 9778.4639 - val_loss: 66166.7578\n",
      "Epoch 876/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 11046.2607 - val_loss: 66067.4688\n",
      "Epoch 877/1000\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 10876.8506 - val_loss: 65985.6562\n",
      "Epoch 878/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 9779.7383 - val_loss: 65979.4297\n",
      "Epoch 879/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 9940.3916 - val_loss: 66034.9297\n",
      "Epoch 880/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 9953.3564 - val_loss: 66100.7031\n",
      "Epoch 881/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 10349.5410 - val_loss: 66163.8438\n",
      "Epoch 882/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 10275.7773 - val_loss: 66287.7422\n",
      "Epoch 883/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 10007.7451 - val_loss: 66373.7266\n",
      "Epoch 884/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 10374.5547 - val_loss: 66443.0078\n",
      "Epoch 885/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 10169.5059 - val_loss: 66383.7578\n",
      "Epoch 886/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 9879.1631 - val_loss: 66175.1484\n",
      "Epoch 887/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 10713.3477 - val_loss: 66030.8516\n",
      "Epoch 888/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 10579.7275 - val_loss: 65939.9297\n",
      "Epoch 889/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 9882.2266 - val_loss: 65808.6328\n",
      "Epoch 890/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 10257.3730 - val_loss: 65656.9688\n",
      "Epoch 891/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 9383.4326 - val_loss: 65512.6211\n",
      "Epoch 892/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 10127.6221 - val_loss: 65424.8750\n",
      "Epoch 893/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 9843.5449 - val_loss: 65401.3164\n",
      "Epoch 894/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 10596.7822 - val_loss: 65417.8281\n",
      "Epoch 895/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 9971.4941 - val_loss: 65504.2617\n",
      "Epoch 896/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 9533.9463 - val_loss: 65591.6016\n",
      "Epoch 897/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 9803.1504 - val_loss: 65613.2969\n",
      "Epoch 898/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 10557.5850 - val_loss: 65681.5234\n",
      "Epoch 899/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 9688.3945 - val_loss: 65706.6094\n",
      "Epoch 900/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 10716.3594 - val_loss: 65775.7344\n",
      "Epoch 901/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 11215.3320 - val_loss: 65888.0312\n",
      "Epoch 902/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 9432.5400 - val_loss: 65934.5781\n",
      "Epoch 903/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 10208.8018 - val_loss: 65820.5234\n",
      "Epoch 904/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 9942.4658 - val_loss: 65757.0703\n",
      "Epoch 905/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 10203.0195 - val_loss: 65737.3750\n",
      "Epoch 906/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 10164.6514 - val_loss: 65743.8750\n",
      "Epoch 907/1000\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 9978.9922 - val_loss: 65669.8203\n",
      "Epoch 908/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 10233.1279 - val_loss: 65572.2578\n",
      "Epoch 909/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 9985.9727 - val_loss: 65554.4219\n",
      "Epoch 910/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 10177.3496 - val_loss: 65509.9844\n",
      "Epoch 911/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 10271.8604 - val_loss: 65467.1133\n",
      "Epoch 912/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 10083.6514 - val_loss: 65473.2031\n",
      "Epoch 913/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 10169.3174 - val_loss: 65505.0664\n",
      "Epoch 914/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 9813.5957 - val_loss: 65490.5664\n",
      "Epoch 915/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 9884.8613 - val_loss: 65420.2656\n",
      "Epoch 916/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 9884.8213 - val_loss: 65289.7383\n",
      "Epoch 917/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 10624.3252 - val_loss: 65271.8242\n",
      "Epoch 918/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 9970.7021 - val_loss: 65402.4414\n",
      "Epoch 919/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 9660.6494 - val_loss: 65536.3203\n",
      "Epoch 920/1000\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 9866.1631 - val_loss: 65584.6172\n",
      "Epoch 921/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 10398.1592 - val_loss: 65592.6016\n",
      "Epoch 922/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 9501.9209 - val_loss: 65565.8203\n",
      "Epoch 923/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 10499.8281 - val_loss: 65471.1250\n",
      "Epoch 924/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 10523.9600 - val_loss: 65400.9609\n",
      "Epoch 925/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 10350.7295 - val_loss: 65415.6133\n",
      "Epoch 926/1000\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 10511.2148 - val_loss: 65489.1602\n",
      "Epoch 927/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 10343.1826 - val_loss: 65606.1250\n",
      "Epoch 928/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 9606.9082 - val_loss: 65685.3750\n",
      "Epoch 929/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 10428.1836 - val_loss: 65776.8672\n",
      "Epoch 930/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 10197.0850 - val_loss: 65915.1484\n",
      "Epoch 931/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 10850.4561 - val_loss: 65920.2734\n",
      "Epoch 932/1000\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 10637.6191 - val_loss: 65795.8281\n",
      "Epoch 933/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 9349.8389 - val_loss: 65665.5781\n",
      "Epoch 934/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 10400.6631 - val_loss: 65456.0781\n",
      "Epoch 935/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 9648.1816 - val_loss: 65138.3867\n",
      "Epoch 936/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 10531.3232 - val_loss: 64825.6406\n",
      "Epoch 937/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 9067.0664 - val_loss: 64603.9258\n",
      "Epoch 938/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 9802.4268 - val_loss: 64512.2852\n",
      "Epoch 939/1000\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 9216.2139 - val_loss: 64507.2148\n",
      "Epoch 940/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 10121.4092 - val_loss: 64575.1914\n",
      "Epoch 941/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 10678.1162 - val_loss: 64699.5000\n",
      "Epoch 942/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 9532.5117 - val_loss: 64857.2734\n",
      "Epoch 943/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 10230.9268 - val_loss: 65086.0508\n",
      "Epoch 944/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 11185.4590 - val_loss: 65337.5859\n",
      "Epoch 945/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 10605.4736 - val_loss: 65605.7500\n",
      "Epoch 946/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 9932.4512 - val_loss: 65810.8672\n",
      "Epoch 947/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 9672.9395 - val_loss: 65963.0938\n",
      "Epoch 948/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 9519.8730 - val_loss: 66012.1016\n",
      "Epoch 949/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 10298.7812 - val_loss: 65902.0859\n",
      "Epoch 950/1000\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 10534.0664 - val_loss: 65724.7031\n",
      "Epoch 951/1000\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 9849.3779 - val_loss: 65643.9453\n",
      "Epoch 952/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 10398.6338 - val_loss: 65665.4531\n",
      "Epoch 953/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 9879.2305 - val_loss: 65745.1953\n",
      "Epoch 954/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 9801.1553 - val_loss: 65853.3281\n",
      "Epoch 955/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 9826.4951 - val_loss: 65950.9219\n",
      "Epoch 956/1000\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 10795.9385 - val_loss: 66007.5938\n",
      "Epoch 957/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 10243.6016 - val_loss: 66047.5703\n",
      "Epoch 958/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 10501.1318 - val_loss: 66076.8047\n",
      "Epoch 959/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 10368.4033 - val_loss: 66121.0938\n",
      "Epoch 960/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 10921.3047 - val_loss: 66196.4766\n",
      "Epoch 961/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 9743.1338 - val_loss: 66259.8359\n",
      "Epoch 962/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 9546.0576 - val_loss: 66311.6484\n",
      "Epoch 963/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 10415.8018 - val_loss: 66359.3359\n",
      "Epoch 964/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 10762.8047 - val_loss: 66364.7500\n",
      "Epoch 965/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 9565.6152 - val_loss: 66434.6250\n",
      "Epoch 966/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 10209.0527 - val_loss: 66597.7812\n",
      "Epoch 967/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 10668.3379 - val_loss: 66771.5938\n",
      "Epoch 968/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 9748.0908 - val_loss: 66906.8438\n",
      "Epoch 969/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 10372.9150 - val_loss: 66932.3125\n",
      "Epoch 970/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 10660.0576 - val_loss: 66906.3203\n",
      "Epoch 971/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 10198.3994 - val_loss: 66863.1562\n",
      "Epoch 972/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 9907.0039 - val_loss: 66840.6406\n",
      "Epoch 973/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 10915.9775 - val_loss: 66890.3984\n",
      "Epoch 974/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 8630.1367 - val_loss: 66945.1172\n",
      "Epoch 975/1000\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 9953.9258 - val_loss: 66954.5000\n",
      "Epoch 976/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 9812.7412 - val_loss: 66987.7578\n",
      "Epoch 977/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 9768.9238 - val_loss: 67069.2188\n",
      "Epoch 978/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 9847.1201 - val_loss: 67128.8125\n",
      "Epoch 979/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 9708.0645 - val_loss: 67120.5000\n",
      "Epoch 980/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 11279.5674 - val_loss: 67177.2188\n",
      "Epoch 981/1000\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 10149.1709 - val_loss: 67169.2109\n",
      "Epoch 982/1000\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 9917.9160 - val_loss: 67088.6484\n",
      "Epoch 983/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 10685.9600 - val_loss: 66949.1328\n",
      "Epoch 984/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 10846.6387 - val_loss: 66778.4453\n",
      "Epoch 985/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 10467.0049 - val_loss: 66497.3438\n",
      "Epoch 986/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 9761.3467 - val_loss: 66210.9922\n",
      "Epoch 987/1000\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 10202.1572 - val_loss: 65968.4531\n",
      "Epoch 988/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 8903.2031 - val_loss: 65753.9297\n",
      "Epoch 989/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 9842.5273 - val_loss: 65563.8828\n",
      "Epoch 990/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 10711.9238 - val_loss: 65450.1289\n",
      "Epoch 991/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 10593.8662 - val_loss: 65489.7148\n",
      "Epoch 992/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 10919.9131 - val_loss: 65579.2109\n",
      "Epoch 993/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 10754.5430 - val_loss: 65589.7500\n",
      "Epoch 994/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 9618.3213 - val_loss: 65502.2617\n",
      "Epoch 995/1000\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 10059.9844 - val_loss: 65323.6602\n",
      "Epoch 996/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 11344.5049 - val_loss: 65200.7500\n",
      "Epoch 997/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 10983.0732 - val_loss: 65176.5234\n",
      "Epoch 998/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 10594.2568 - val_loss: 65223.0352\n",
      "Epoch 999/1000\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 11229.1914 - val_loss: 65238.4648\n",
      "Epoch 1000/1000\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 10944.1553 - val_loss: 65269.3164\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=1000, batch_size=32, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c27b0ee-a0ce-4700-90d9-f7aaedd79174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_prices = model.predict(X_test)\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(y_test, color='blue', label='Actual Closing Price')\n",
    "plt.plot(predicted_prices, color='red', label='Predicted Closing Price')\n",
    "plt.title('Actual vs Predicted Closing Prices')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Close Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fedf51d-1deb-47e0-9565-4f683765203f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
